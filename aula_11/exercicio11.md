# Orientação de Exercícios de PLN

## Objetivo

Nas últimas duas aulas foram descritas a implementação do GPT. Foram apresentadas a implementação do mecanismo de Atenção e todas as camadas da arquitetura Transformer. Porém, ainda restou a parte de pré-treinamento. Assim, para cobrir essa última e importante parte, o exercícios corresponde ao Capítulo 5 do livro do Sebastian Raschka "Build a Large Language Model From Scratch".
Acompanhe o conteúdo no notebook abertamente disponível no github:  [Capitulo 5](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb).

O trabalho não é treinar um modelo, o que é caro e exige tempo e recurso computacional. Assim, o seu trabalho é carregar um modelo já treinado e transferir os pesos para uma instância do seu modelo. Os passos para realização de transferência de pesos estão descritos na Seção 5.5 (5.5 Loading pretrained weights from OpenAI). 

Data da entrega: **20/02/2024**

---

### Crie um **notebook** que:
   - Carregue o GPT2 e transfira os pesos para o seu modelo.
   - Faça um exemplo de geração de texto!   

---

## Entregáveis

1. **Apenas um Notebook**:
   

---
